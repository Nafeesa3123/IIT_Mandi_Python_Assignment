{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3912be35-0f02-40b5-ab35-400a793ac299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "\n",
      "toboggan thight amused foreshows silbergroschen bardess overstaying outfool alang barche septolet unreiterated intreated antilacrosser igraine vocabularied windchest gerontomorphosis erinose sappiest jigote apocamphoric preimbibed shivah unreprimanding preconditioned zoon shuteye tubercularized allophanamide phylarchical gait crankpin birostrate unpaying rattletybang spatangida hepatophlebotomy bejumble raced rattletybang unpaying internists cuspidated decuss aretalogy emphlysis teledus revengeless lieutenancy zooecium jackbird aretalogy theomachia misfires abdominocentesis cristi rookeried teledus infatuatedness stipulating radiography unspeedily illing candlefish papilionid bejumble improver rotiferous togs palesman elaeothesia icterode taplet elaphurine airified gaiters fagins muskrats cucurb aequor dasya imperatorious rhabdophane supersacrifice bronzine annexing billycan coenomonoecism vitrifiable leadiest tough merchant hepatophlebotomy gerontomorphosis overstaying appetite overneatness ushabtiu mutagenicity slubbered overdelighted posterity rookeried realization intermarriages opinable jackbird wame kichel gomer chined cohibitor protoprotestant nosairi fawns makebate thight peto tetramethylene lieutenancy unpulverize chirpily lagnappe lagnappe protorosaur unfickle arizonans fagins regardlessness unverified stercorin leucetta grog reticency mincingness amazonism toboggan telic unverified essart semiabstraction bardess pachypod dasya stoneroot antilacrosser fagins amazonism fibrinolysin gonoblast whippowill chumminess hardhack annihilating trickly reposals bawling duvetines skidways involutorial lagnappe housekkept populists telic regardlessness premarried aitchpiece premarried septolet overproduction aurophobia intertriglyph sussex mathematician shilla amazonism prepurchasing noncoordinating intermarriages bayadeer distad revoltress guyline subdistinguish mirinesses celastraceous gerontomorphosis sorbonical fossils doub defoul vervenia antiprofiteering tkt raced arizonans threeness internists tiro uncaptivative kleptomaniacs genuflex milltail hexadactyle allmouth hexadactyle handful sterilized allophanamide prefectorial whippowill gomer weskit crozle improver tough toboggan quercitannic overneatness stackhousiaceous inflexionally defoul unantagonising adiadokokinesia paraphysical milltail whippowill prehatred gangion aequor unbench zooecium grog birostrate unrelentor fulfillers ingruent plumbing alang arizonans telecasters mollberg adarme vocabularied chronographs tkt rotodyne puzzleheadedness trickly\n",
      "\n",
      "==================================================\n",
      "\n",
      "Top 20 Most Common Words:\n",
      "toboggan: 3\n",
      "gerontomorphosis: 3\n",
      "fagins: 3\n",
      "lagnappe: 3\n",
      "arizonans: 3\n",
      "amazonism: 3\n",
      "whippowill: 3\n",
      "thight: 2\n",
      "bardess: 2\n",
      "overstaying: 2\n",
      "alang: 2\n",
      "septolet: 2\n",
      "antilacrosser: 2\n",
      "vocabularied: 2\n",
      "allophanamide: 2\n",
      "birostrate: 2\n",
      "unpaying: 2\n",
      "rattletybang: 2\n",
      "hepatophlebotomy: 2\n",
      "bejumble: 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "df = pd.read_csv(\"words_pos.csv\")  \n",
    "\n",
    "words_list = df['word'].tolist()\n",
    "\n",
    "limited_words_list = random.sample(words_list, min(500, len(words_list)))\n",
    "\n",
    "generated_text = \" \".join(random.choices(limited_words_list, k=250))\n",
    "\n",
    "with open(\"generated_text_repeated.txt\", \"w\") as f:\n",
    "    f.write(generated_text)\n",
    "\n",
    "print(\"Generated Text:\\n\")\n",
    "print(generated_text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "text_data = generated_text.lower()\n",
    "text_data = re.sub(r\"[0-9]+\", \" \", text_data)\n",
    "text_data = text_data.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "words = text_data.split()\n",
    "\n",
    "stop_words = {\"a\",\"an\",\"the\",\"and\",\"or\",\"in\",\"on\",\"at\",\"to\",\"for\",\"of\",\"is\",\"it\",\n",
    "              \"this\",\"that\",\"with\",\"as\",\"by\",\"from\",\"are\",\"was\",\"were\",\"be\",\"been\",\n",
    "              \"being\",\"i\",\"you\",\"he\",\"she\",\"they\",\"them\",\"we\",\"us\",\"our\",\"your\",\n",
    "              \"his\",\"her\",\"their\",\"but\",\"if\",\"so\",\"than\",\"too\",\"very\",\"can\",\"will\",\n",
    "              \"just\",\"not\",\"do\",\"does\",\"did\",\"have\",\"has\",\"had\"}\n",
    "\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "word_counts = Counter(filtered_words)\n",
    "\n",
    "top_20 = word_counts.most_common(20)\n",
    "\n",
    "print(\"Top 20 Most Common Words:\")\n",
    "for word, count in top_20:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "\n",
    "with open(\"top_20_words.txt\", \"w\") as f:\n",
    "    for word, count in top_20:\n",
    "        f.write(f\"{word}: {count}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc1abb1-b24a-4bcb-b91a-9648eecbd9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
